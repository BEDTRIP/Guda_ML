{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d791f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import surprise, sklearn, sklearn.model_selection, tqdm\n",
    "d = pd.read_csv('example_data.csv', sep='\\t')\n",
    "d\n",
    "# если у вас id имеет строковый тип, то лучше его сконвертировать в int, например, такой командой:\n",
    "# d['user_id'] = sklearn.preprocessing.LabelEncoder().fit_transform(d['user_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988c449b",
   "metadata": {},
   "source": [
    "# Предварительные размышления\n",
    "\n",
    "В предоставленных данных находятся рейтинги товаров, выставленные пользователями, которые их покупали. Магазину выгодно порекомендовать товар, который пользователь с большой вероятностью купит. Какой рекомендовать: с небольшим количеством оценок, но все 5, или тот, который покупало множество людей, но рейтинг ниже? \n",
    "\n",
    "Алгоритмы библиотек рекомендательных систем, например, [Suprise](https://surpriselib.com/) стремятся предсказать рейтинг, но нам нужно предсказывать факт покупки. Изменим наш датасет и оценки качества так, чтобы предсказывался и проверялся факт покупки товара."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461788b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "d.rename({'rating':'buy'}, axis=1, inplace=True)\n",
    "d['buy'] = 1\n",
    "d\n",
    "# теперь в датасете отражен только факт покупки товара (все строки содержат buy=1), \n",
    "# а те пары (user_id, item_id), которые не встречаются, соответсвуют не купленным товарам"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5ccb9e-608a-48d4-97b1-6ef02d67d815",
   "metadata": {},
   "source": [
    "# Посмотрим на датасет\n",
    "\n",
    "С помощью метода `Dataframe.groupby('столбец1')['столбец2'].count()` найдите количество товаров, купленных каждым пользователем, и количество пользователей, купивших каждый товар. \n",
    "\n",
    "Функцией `np.unique(..., return_counts=True)` вычислите статистику: \n",
    "- количество случайных (не постоянных) покупателей (купили только один товар)\n",
    "- насколько богат самый постоянный покупатель (сколько максимум товаров купил один человек)\n",
    "- сколько непопулярных товаров (купили только один раз)\n",
    "- насколько популярны товары первой необходимости (сколько максимум людей купили один товар)\n",
    "\n",
    "С помощью функции `seaborn.histplot` с параметром `log_scale=True` нарисуйте две гистограммы: \n",
    "- распределение популярностей товаров (количеств купивших их людей)\n",
    "- распределение количеств покупок (сколько людей купили только 1 товар, 2 товара, 3 товара, ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0b7c6b-83b3-4866-8fe0-b261202d7adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# место для кода"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8533cb2f",
   "metadata": {},
   "source": [
    "# Подготовка обучающей выборки\n",
    "\n",
    "Делим множество пользователей на train и test. Ответьте в комментариях на вопрос: чем отличается проверка, когда мы делим на train и test пользователей, от проверки, когда мы делим на train и test строки датасета d? (10% баллов)\n",
    "\n",
    "Изначально train будет содержать только положительные записи о купленных товарах. Туда нужно добавить еще какое-то количество не купленных, иначе алгоритм всем будет предсказывать только 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4853d057",
   "metadata": {},
   "outputs": [],
   "source": [
    "cold_start = True\n",
    "\n",
    "all_users = np.unique(d['user_id'])\n",
    "print('Общее число пользователей:', len(all_users))\n",
    "\n",
    "# уменьшите, если вам не хватает оперативной памяти\n",
    "train_size=4000\n",
    "test_size=100\n",
    "\n",
    "if cold_start:\n",
    "    assert train_size+test_size < len(all_users)\n",
    "    train_users, test_users = sklearn.model_selection.train_test_split(all_users, \n",
    "                    train_size=train_size, test_size=test_size, random_state=0)\n",
    "else:\n",
    "    train_users = np.random.choice(all_users, size=train_size, replace=False)\n",
    "    assert test_size <= train_size\n",
    "    test_users = np.random.choice(train_users, size=test_size, replace=False)\n",
    "\n",
    "d_train = d.loc[np.isin(d['user_id'], train_users)].reset_index(drop=True)\n",
    "d_test = d.loc[np.isin(d['user_id'], test_users)].reset_index(drop=True)\n",
    "\n",
    "print('Размер обучающей выборки', len(d_train))\n",
    "print('Среднее число покупок у одного человека', len(d_train)/train_size)\n",
    "\n",
    "# добавляем в d_train товары, которые пользователи не покупали и присваиваем им минимальный рейтинг\n",
    "# у меня самый хороший результат получился, когда добавляешь столько же не купленных товаров, сколько\n",
    "# в среднем покупают пользователи\n",
    "toAdd_for_each_user = 30\n",
    "toAdd = np.zeros((toAdd_for_each_user,3))\n",
    "all_items = np.unique(np.concatenate((d_train['item_id'],d_test['item_id'])))\n",
    "n_items = len(all_items)\n",
    "print('Общее число товаров:', n_items)\n",
    "np.random.seed(0)\n",
    "for i in tqdm.tqdm(range(train_size)):\n",
    "    user_id = train_users[i]\n",
    "    ind_for_1_user = np.where(d_train['user_id'] == user_id)[0]\n",
    "    buy = d_train.loc[ind_for_1_user,'item_id']\n",
    "    not_buy = id товаров, которые этот пользователь не покупал (см. np.setdiff1d)  # TODO!!!\n",
    "    toAdd[:,0] = user_id\n",
    "    toAdd[:,1] = случайное подмножество not_buy нужного размера  # TODO!!!\n",
    "    if not cold_start and len(buy) > 1:\n",
    "        # выбрасываем из train часть купленных товаров, чтобы они попали в тест\n",
    "        d_train.drop(ind_for_1_user[len(ind_for_1_user)//2:], axis=0, inplace=True)\n",
    "    d_train = pd.concat((d_train, pd.DataFrame(toAdd, columns=d_train.columns)), axis=0)\n",
    "    d_train.reset_index(drop=True, inplace=True)\n",
    "print('Размер расширенной обучающей выборки', len(d_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc59c89",
   "metadata": {},
   "source": [
    "# Тренировка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903b0871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Порядок столбцов для surprise очень важен: user_id, item_id и рейтинг\n",
    "surprise_d_train = surprise.Dataset.load_from_df(d_train[['user_id','item_id','buy']], \n",
    "                        surprise.Reader(rating_scale=(0,1))).build_full_trainset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027325fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "method = surprise.SVD()\n",
    "method.fit(surprise_d_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc54345",
   "metadata": {},
   "source": [
    "# Расширение тестового датасета\n",
    "\n",
    "Расширим test товарами, которые пользователи не покупали, и предскажем факт покупки для расширенного test. В отличие от train здесь придется добавить все без исключения товары, чтобы предсказать рекомендации для всех. \n",
    "\n",
    "Так как количество товаров очень большое, то в тесте не должно быть много пользователей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9f4995",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_true_test_for_one_user(d_test, user_id):\n",
    "    if cold_start:\n",
    "        # пользователь не встречается в train вовсе - добавляем в test все товары\n",
    "        extended_true_test = np.zeros(n_items)\n",
    "        ind_for_1_user = d_test['user_id'] == user_id\n",
    "        buy = id товаров, которые этот пользователь покупал  # TODO!!!\n",
    "        extended_true_test[индексы (логические) тех id из all_items, которые покупал] = 1  # TODO!!! (см. np.isin)\n",
    "        return extended_true_test, all_items\n",
    "    else:\n",
    "        # тестируем только на купленных товарах данного пользователя в test \n",
    "        # и на тех некупленных товарах, факты о некупли которых не содержатся в train\n",
    "        ind_for_1_user = d_test['user_id'] == user_id\n",
    "        buy_test = np.unique(d_test.loc[d_test['user_id'] == user_id, 'item_id'])\n",
    "        buy_train = np.unique(d_train.loc[(d_train['user_id']==user_id) & (d_train['buy']==1), 'item_id'])\n",
    "        all_buy = np.union1d(buy_train, buy_test)\n",
    "        not_buy = np.setdiff1d(all_items, all_buy)\n",
    "        not_buy_train = np.unique(d_train.loc[(d_train['user_id']==user_id) & (d_train['buy']==0), 'item_id'])\n",
    "        not_buy_test = np.setdiff1d(not_buy, not_buy_train)\n",
    "        all_items_test = np.union1d(buy_test, not_buy_test)\n",
    "        extended_true_test = np.zeros(len(all_items_test))\n",
    "        extended_true_test[np.isin(all_items_test, buy_test)] = 1\n",
    "        return extended_true_test, all_items_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133b162a",
   "metadata": {},
   "source": [
    "# Предсказание"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8947773",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predicted_test_for_one_user(method, user_id, all_items_for_1_user):\n",
    "    extended_predicted_test = np.zeros(len(all_items_for_1_user))\n",
    "    for i, item_id in enumerate(all_items_for_1_user):\n",
    "        extended_predicted_test[i] = предсказание для user_id и i-того товара из all_items  # TODO!!!\n",
    "    return extended_predicted_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494ac866",
   "metadata": {},
   "source": [
    "# Оценка качества [MAP@k](https://habr.com/ru/companies/econtenta/articles/303458/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78de006",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AP_at_k(predictions_for_1_user, true_for_1_user, k):\n",
    "    max_ind = np.argpartition(-predictions_for_1_user, k)[:k]\n",
    "    max_predictions = predictions_for_1_user[max_ind]\n",
    "    true = true_for_1_user[max_ind]\n",
    "    # сортируем максимальные k предсказаний\n",
    "    i = np.argsort(-max_predictions)\n",
    "    max_predictions = max_predictions[i]\n",
    "    true = true[i]\n",
    "    # считаем AP, усредняя Precision для всех 1\n",
    "    ones_ind = np.where(true == 1)[0]\n",
    "    if len(ones_ind) == 0: return 0\n",
    "    precision = np.zeros(len(ones_ind))\n",
    "    for j in range(len(ones_ind)):\n",
    "        ind_of_one = ones_ind[j]\n",
    "        precision[j] = Precision для (ind_of_one+1) первых элементов  # TODO!!!\n",
    "    return np.mean(precision)\n",
    "\n",
    "k = 100\n",
    "APs = np.zeros(test_size)\n",
    "for i in tqdm.tqdm(range(test_size)):\n",
    "    user_id = test_users[i]\n",
    "    true_for_1_user, all_items_for_1_user =   # TODO!!!\n",
    "    predictions_for_1_user =   # TODO!!!\n",
    "    APs[i] = AP_at_k(predictions_for_1_user, true_for_1_user, k)\n",
    "\n",
    "MAP = np.mean(APs)\n",
    "print(f'MAP@{k} =', MAP)\n",
    "correct = 0.05341 if cold_start else 0.04978\n",
    "assert np.isclose(MAP,correct,atol=0.002), 'В вашу программу закралась ошибка. Найдите и исправьте ее'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bda8c80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
